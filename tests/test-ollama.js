/**
 * Test Ollama Integration
 * 
 * Tests Ollama integration for S.I.R.I.U.S. functionality
 */

import ollamaService from '../src/services/ollamaService.js';

async function testOllama() {
  console.log('üß™ Testing Ollama Integration for S.I.R.I.U.S.\n');
  
  try {
    // 1. Check if Ollama is available
    console.log('1Ô∏è‚É£ Checking Ollama status...');
    const isAvailable = await ollamaService.checkOllamaStatus();
    
    if (!isAvailable) {
      console.log('‚ùå Ollama is not running');
      console.log('üí° Install Ollama: curl -fsSL https://ollama.ai/install.sh | sh');
      console.log('üí° Start Ollama: ollama serve');
      console.log('üí° Download model: ollama pull llama3.1:8b');
      return;
    }
    
    console.log('‚úÖ Ollama is running!\n');
    
    // 2. List available models
    console.log('2Ô∏è‚É£ Checking available models...');
    const models = await ollamaService.listModels();
    console.log('üìã Available models:');
    models.forEach(model => {
      console.log(`   - ${model.name} (${model.size} bytes)`);
    });
    console.log();
    
    // 3. Test basic response generation
    console.log('3Ô∏è‚É£ Testing basic response generation...');
    const startTime = Date.now();
    const response = await ollamaService.generateResponse('Hello, how are you?', {
      model: ollamaService.MODELS.BALANCED,
      maxTokens: 50
    });
    const endTime = Date.now();
    
    console.log(`‚úÖ Response generated in ${endTime - startTime}ms:`);
    console.log(`   "${response}"\n`);
    
    // 4. Test intent extraction
    console.log('4Ô∏è‚É£ Testing intent extraction...');
    const intent = await ollamaService.extractIntent("What's on my schedule today?");
    console.log('‚úÖ Intent extracted:');
    console.log(`   Intent: ${intent.intent}`);
    console.log(`   Confidence: ${intent.confidence}`);
    console.log(`   Parameters:`, intent.parameters);
    console.log();
    
    // 5. Test daily digest summary
    console.log('5Ô∏è‚É£ Testing daily digest summary...');
    const mockData = {
      calendarEvents: [
        {
          summary: 'Team Standup',
          start: '2024-01-15T09:00:00Z'
        },
        {
          summary: 'Client Meeting',
          start: '2024-01-15T14:00:00Z'
        }
      ],
      todos: [
        {
          title: 'Complete API documentation',
          priority: 'high',
          dueDate: '2024-01-15T17:00:00Z'
        }
      ],
      emails: [
        {
          subject: 'Project Update',
          sender: 'manager@company.com',
          priority: 'high'
        }
      ]
    };
    
    const summary = await ollamaService.generateIntelligentSummary(mockData);
    console.log('‚úÖ Daily digest summary generated:');
    console.log(`   Overview: ${summary.overview}`);
    console.log(`   Priorities: ${summary.priorities.length} items`);
    console.log(`   Actions: ${summary.suggestedActions.length} suggestions\n`);
    
    // 6. Performance comparison
    console.log('6Ô∏è‚É£ Performance Analysis...');
    console.log('üìä Ollama Performance:');
    console.log('   ‚úÖ No API costs');
    console.log('   ‚úÖ No rate limits');
    console.log('   ‚úÖ Privacy (local processing)');
    console.log('   ‚úÖ Offline capability');
    console.log('   ‚úÖ Customizable models');
    console.log('   ‚ö†Ô∏è  Requires local resources');
    console.log('   ‚ö†Ô∏è  Initial model download');
    
    console.log('\nüéâ Ollama integration test complete!');
    console.log('üöÄ Ready to use with S.I.R.I.U.S.');
    
  } catch (error) {
    console.error('‚ùå Error testing Ollama:', error.message);
    console.log('\nüí° Troubleshooting:');
    console.log('1. Make sure Ollama is installed and running');
    console.log('2. Check if models are downloaded: ollama list');
    console.log('3. Try downloading a model: ollama pull llama3.1:8b');
  }
}

testOllama(); 